{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farkhanal/analisis-citra-wajah/blob/main/Training_Set_(ArcFace).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_8B0Gawlg4R",
        "outputId": "a6350682-f6b9-4361-bc9a-b1aaa44f6761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbUfnXDxmC5j",
        "outputId": "7709a8bf-e86b-4dd9-cc80-ba9d7712f978"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Downloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lz4, mtcnn\n",
            "Successfully installed lz4-4.3.3 mtcnn-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mtcnn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgsQCVlQlr4q",
        "outputId": "a4991dcf-2d22-450a-fcb7-b4ab538a9598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proses deteksi dan pemotongan wajah selesai!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries yang diperlukan\n",
        "import os\n",
        "from mtcnn import MTCNN\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Inisialisasi MTCNN face detector\n",
        "detector = MTCNN()\n",
        "\n",
        "# Path dataset dan path penyimpanan output\n",
        "base_path = '/content/drive/My Drive/Colab Notebooks/nist_2/train/'\n",
        "output_path = '/content/drive/My Drive/Colab Notebooks/nist_2/train/FaceDetection/'\n",
        "\n",
        "# Membuat direktori FaceDetection jika belum ada\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "# Iterasi melalui setiap subfolder yang ada di base_path\n",
        "for subfolder in os.listdir(base_path):\n",
        "    subfolder_path = os.path.join(base_path, subfolder)\n",
        "\n",
        "    # Memeriksa apakah path adalah sebuah direktori\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        output_folder_path = os.path.join(output_path, subfolder)\n",
        "\n",
        "        # Membuat subfolder FaceDetection per label jika belum ada\n",
        "        if not os.path.exists(output_folder_path):\n",
        "            os.makedirs(output_folder_path)\n",
        "\n",
        "        # Iterasi melalui setiap file dalam subfolder\n",
        "        for file_name in os.listdir(subfolder_path):\n",
        "            if file_name.endswith('.ppm'):  # Memeriksa format PPM\n",
        "                file_path = os.path.join(subfolder_path, file_name)\n",
        "                image = Image.open(file_path).convert('RGB')  # Membuka gambar\n",
        "\n",
        "                # Konversi gambar ke array numpy untuk deteksi\n",
        "                image_array = np.array(image)\n",
        "                faces = detector.detect_faces(image_array)  # Deteksi wajah\n",
        "\n",
        "                # Mengecek apakah ada wajah yang terdeteksi\n",
        "                if faces:\n",
        "                    # Ambil bounding box dari wajah pertama yang terdeteksi\n",
        "                    x, y, width, height = faces[0]['box']\n",
        "                    cropped_face = image.crop((x, y, x + width, y + height))\n",
        "\n",
        "                    # Simpan gambar wajah yang telah dipotong\n",
        "                    output_image_path = os.path.join(output_folder_path, file_name)\n",
        "                    cropped_face.save(output_image_path)\n",
        "\n",
        "                    # Tampilkan gambar yang telah dipotong\n",
        "                    cropped_face.show()\n",
        "\n",
        "print(\"Proses deteksi dan pemotongan wajah selesai!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXnR7YCYpQ5Q",
        "outputId": "9a4d1ff8-e242-40d8-94ee-ef1ce7ed21dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proses augmentasi selesai dan gambar tersimpan!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "# Path dataset yang sudah dideteksi dan path penyimpanan hasil augmentasi\n",
        "base_path = '/content/drive/My Drive/Colab Notebooks/nist_2/train/FaceDetection/'\n",
        "output_path = '/content/drive/My Drive/Colab Notebooks/nist_2/AugmentedData/'\n",
        "\n",
        "# Membuat direktori AugmentedData jika belum ada\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n",
        "\n",
        "# Fungsi untuk melakukan augmentasi\n",
        "def augment_image(image):\n",
        "    augmented_images = []\n",
        "\n",
        "    # Rotasi\n",
        "    angles = [-15, 15, -30, 30]\n",
        "    for angle in angles:\n",
        "        rotated = image.rotate(angle)\n",
        "        augmented_images.append(rotated)\n",
        "\n",
        "    # Flipping\n",
        "    flipped_h = ImageOps.mirror(image)\n",
        "    augmented_images.append(flipped_h)\n",
        "\n",
        "    flipped_v = ImageOps.flip(image)\n",
        "    augmented_images.append(flipped_v)\n",
        "\n",
        "    # Pencahayaan dan Kontras\n",
        "    enhancer = ImageEnhance.Brightness(image)\n",
        "    bright_image = enhancer.enhance(1.5)\n",
        "    dark_image = enhancer.enhance(0.5)\n",
        "    augmented_images.append(bright_image)\n",
        "    augmented_images.append(dark_image)\n",
        "\n",
        "    enhancer_contrast = ImageEnhance.Contrast(image)\n",
        "    high_contrast_image = enhancer_contrast.enhance(1.5)\n",
        "    low_contrast_image = enhancer_contrast.enhance(0.5)\n",
        "    augmented_images.append(high_contrast_image)\n",
        "    augmented_images.append(low_contrast_image)\n",
        "\n",
        "    # Gaussian Noise\n",
        "    def add_gaussian_noise(image_np):\n",
        "        mean = 0\n",
        "        std = 10\n",
        "        gauss = np.random.normal(mean, std, image_np.shape).astype('uint8')\n",
        "        noisy = cv2.add(image_np, gauss)\n",
        "        return Image.fromarray(noisy)\n",
        "\n",
        "    image_np = np.array(image)\n",
        "    augmented_images.append(add_gaussian_noise(image_np))\n",
        "\n",
        "    # Blurring\n",
        "    blurred = image.filter(ImageFilter.GaussianBlur(radius=2))\n",
        "    augmented_images.append(blurred)\n",
        "\n",
        "    # Warna atau Intensitas (Color Jitter)\n",
        "    enhancer_color = ImageEnhance.Color(image)\n",
        "    color_enhanced = enhancer_color.enhance(1.5)\n",
        "    color_reduced = enhancer_color.enhance(0.5)\n",
        "    augmented_images.append(color_enhanced)\n",
        "    augmented_images.append(color_reduced)\n",
        "\n",
        "    return augmented_images\n",
        "\n",
        "# Iterasi melalui setiap subfolder di FaceDetection\n",
        "for subfolder in os.listdir(base_path):\n",
        "    subfolder_path = os.path.join(base_path, subfolder)\n",
        "    output_folder_path = os.path.join(output_path, subfolder)\n",
        "\n",
        "    # Membuat subfolder di AugmentedData jika belum ada\n",
        "    if not os.path.exists(output_folder_path):\n",
        "        os.makedirs(output_folder_path)\n",
        "\n",
        "    # Iterasi melalui setiap file dalam subfolder\n",
        "    for file_name in os.listdir(subfolder_path):\n",
        "        if file_name.endswith('.ppm'):\n",
        "            file_path = os.path.join(subfolder_path, file_name)\n",
        "            image = Image.open(file_path).convert('RGB')  # Membuka gambar\n",
        "\n",
        "            # Lakukan augmentasi\n",
        "            augmented_images = augment_image(image)\n",
        "\n",
        "            # Simpan setiap gambar yang sudah diaugmentasi\n",
        "            for i, aug_img in enumerate(augmented_images):\n",
        "                aug_file_name = f\"{file_name.split('.')[0]}_aug_{i}.ppm\"\n",
        "                aug_file_path = os.path.join(output_folder_path, aug_file_name)\n",
        "                aug_img.save(aug_file_path)\n",
        "\n",
        "print(\"Proses augmentasi selesai dan gambar tersimpan!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCOspPkwrbZI",
        "outputId": "489a0838-6744-47e9-c372-6a576a689e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total gambar yang digabungkan dari augmentasi: 7752\n",
            "Contoh label yang dimuat: {'S185', 'S130', 'S013', 'S325', 'S383', 'S118', 'S153', 'S375', 'S321', 'S373', 'S133', 'S367', 'S272', 'S335', 'S336', 'S331', 'S324', 'S243', 'S058', 'S380', 'S117', 'S198', 'S138', 'S033', 'S108', 'S180', 'S389', 'S228', 'S427', 'S006', 'S405', 'S350', 'S195', 'S099', 'S258', 'S407', 'S227', 'S273', 'S390', 'S297', 'S387', 'S250', 'S428', 'S124', 'S073', 'S261', 'S226', 'S030', 'S346', 'S098', 'S044', 'S232', 'S036', 'S206', 'S174', 'S254', 'S259', 'S051', 'S392', 'S425', 'S398', 'S270', 'S283', 'S391', 'S385', 'S201', 'S052', 'S256', 'S381', 'S352', 'S429', 'S296', 'S364', 'S132', 'S222', 'S284', 'S396', 'S393', 'S354', 'S032', 'S031', 'S355', 'S341', 'S111', 'S288', 'S045', 'S307', 'S236', 'S096', 'S173', 'S394', 'S400', 'S409', 'S027', 'S239', 'S414', 'S310', 'S088', 'S202', 'S191', 'S412', 'S112', 'S093', 'S351', 'S253', 'S142', 'S223', 'S059', 'S220', 'S416', 'S008', 'S386', 'S134', 'S353', 'S417', 'S193', 'S382', 'S395', 'S022', 'S015', 'S295', 'S182', 'S163', 'S316', 'S054', 'S282', 'S225', 'S423', 'S309', 'S095', 'S166', 'S421', 'S214', 'S148', 'S029', 'S023', 'S419', 'S263', 'S357', 'S422', 'S001', 'S420', 'S333', 'S249', 'S101', 'S411', 'S212', 'S171', 'S413', 'S146', 'S397', 'S404', 'S315', 'S399', 'S280', 'S406', 'S376', 'S415', 'S300', 'S215', 'S065', 'S076', 'S418', 'S403', 'S150', 'S078', 'S199', 'S401', 'S219', 'S291', 'S120', 'S164', 'S069', 'S068', 'S145', 'S402', 'S285', 'S408', 'S388', 'S085', 'S046', 'S048', 'S426', 'S384', 'S240', 'S313', 'S203', 'S194', 'S190', 'S064', 'S304'}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Daftar direktori augmentasi yang akan digabungkan\n",
        "augmentation_directories = [\n",
        "    '/content/drive/My Drive/Colab Notebooks/nist_2/AugmentedData/',\n",
        "    '/content/drive/My Drive/Colab Notebooks/nist_2/sample train_augment/'\n",
        "]\n",
        "\n",
        "# List untuk menyimpan data gambar dan label\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Loop melalui setiap direktori augmentasi\n",
        "for directory in augmentation_directories:\n",
        "    for subfolder in os.listdir(directory):\n",
        "        subfolder_path = os.path.join(directory, subfolder)\n",
        "        if os.path.isdir(subfolder_path):  # Pastikan hanya membaca subfolder\n",
        "            # Loop melalui setiap file gambar dalam subfolder\n",
        "            for file_name in os.listdir(subfolder_path):\n",
        "                if file_name.endswith('.ppm'):\n",
        "                    file_path = os.path.join(subfolder_path, file_name)\n",
        "                    # Baca gambar dan simpan label sesuai nama subfolder (misal: S001, S002, dst.)\n",
        "                    image = Image.open(file_path).convert('RGB')\n",
        "                    images.append(image)\n",
        "                    labels.append(subfolder)  # Label sesuai dengan nama subfolder\n",
        "\n",
        "# Menampilkan total gambar yang berhasil dimuat\n",
        "print(f\"Total gambar yang digabungkan dari augmentasi: {len(images)}\")\n",
        "print(f\"Contoh label yang dimuat: {set(labels)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G2lrCSUxFmw",
        "outputId": "31307c12-beb1-4955-83b9-c062f3ee8c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (1.4.2)\n",
            "Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.3.3)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install mtcnn opencv-python pillow matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDKuYXdAvvN9",
        "outputId": "179f23e7-735d-4a6a-828b-2f9ccd063994"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Face alignment selesai untuk semua direktori!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from mtcnn import MTCNN\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Daftar direktori input untuk face alignment\n",
        "input_directories = [\n",
        "    '/content/drive/My Drive/Colab Notebooks/nist_2/AugmentedData/',\n",
        "    '/content/drive/My Drive/Colab Notebooks/nist_2/sample train_augment/'\n",
        "]\n",
        "# Direktori output untuk hasil face alignment\n",
        "output_directory = '/content/drive/My Drive/Colab Notebooks/nist_2/AlignedData/'\n",
        "\n",
        "# Inisialisasi detektor MTCNN\n",
        "detector = MTCNN()\n",
        "\n",
        "# face alignment berdasarkan posisi mata\n",
        "def align_face(image, keypoints):\n",
        "    left_eye = keypoints['left_eye']\n",
        "    right_eye = keypoints['right_eye']\n",
        "\n",
        "    # Tentukan sudut antara mata kiri dan kanan\n",
        "    delta_x = right_eye[0] - left_eye[0]\n",
        "    delta_y = right_eye[1] - left_eye[1]\n",
        "    angle = np.degrees(np.arctan2(delta_y, delta_x))\n",
        "\n",
        "    # Hitung titik tengah antara kedua mata dan konversi ke float\n",
        "    eyes_center = (float((left_eye[0] + right_eye[0]) / 2), float((left_eye[1] + right_eye[1]) / 2))\n",
        "\n",
        "    # Dapatkan rotasi matriks untuk meluruskan gambar\n",
        "    rot_mat = cv2.getRotationMatrix2D(eyes_center, angle, scale=1.0)\n",
        "\n",
        "    # Lakukan rotasi gambar\n",
        "    aligned_face = cv2.warpAffine(np.array(image), rot_mat, (image.width, image.height))\n",
        "\n",
        "    return Image.fromarray(aligned_face)\n",
        "\n",
        "# Proses face alignment untuk setiap direktori input\n",
        "for directory in input_directories:\n",
        "    for subfolder in os.listdir(directory):\n",
        "        subfolder_path = os.path.join(directory, subfolder)\n",
        "        if os.path.isdir(subfolder_path):\n",
        "            # Buat subfolder untuk output face alignment jika belum ada\n",
        "            output_subfolder = os.path.join(output_directory, subfolder)\n",
        "            os.makedirs(output_subfolder, exist_ok=True)\n",
        "\n",
        "            for file_name in os.listdir(subfolder_path):\n",
        "                if file_name.endswith('.ppm'):\n",
        "                    file_path = os.path.join(subfolder_path, file_name)\n",
        "                    image = Image.open(file_path).convert('RGB')\n",
        "                    image_array = np.array(image)\n",
        "\n",
        "                    # Deteksi wajah dan landmark\n",
        "                    result = detector.detect_faces(image_array)\n",
        "\n",
        "                    if result:\n",
        "                        # Ambil bounding box dan landmark wajah\n",
        "                        keypoints = result[0]['keypoints']\n",
        "\n",
        "                        # Face alignment menggunakan posisi mata\n",
        "                        aligned_image = align_face(image, keypoints)\n",
        "\n",
        "                        # Simpan hasil face alignment di direktori output\n",
        "                        aligned_image.save(os.path.join(output_subfolder, file_name))\n",
        "\n",
        "print(\"Face alignment selesai untuk semua direktori!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVeWpBhaMkS9",
        "outputId": "2b688d0d-3b92-4280-967c-d81c3f4d05e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/439.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m430.1/439.5 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.26.4)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from insightface) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from insightface) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from insightface) (3.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from insightface) (10.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from insightface) (1.5.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from insightface) (0.24.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from insightface) (3.0.11)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from insightface) (1.4.15)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from insightface) (3.11.0)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (2.9.2)\n",
            "Requirement already satisfied: albucore>=0.0.15 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.0.16)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (4.10.0.84)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (2.8.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\n",
            "Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp310-cp310-linux_x86_64.whl size=1055395 sha256=9b16be782b6930f6f3cb5444db617ab8895843c5a1ce17ddcb10f642197b7822\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/d0/80/e3773fb8b6d1cca87ea1d33d9b1f20a223a6493c896da249b5\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, humanfriendly, coloredlogs, onnxruntime, insightface\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.7.3 onnx-1.17.0 onnxruntime-1.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install insightface onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyXH1SVUz68y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d2791a-8253-4974-fc18-d55a4b1d4a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.20 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "download_path: /root/.insightface/models/buffalo_l\n",
            "Downloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 281857/281857 [00:10<00:00, 27536.08KB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing S420:   0%|          | 0/11 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n",
            "Processing S420: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n",
            "Processing S422: 100%|██████████| 10/10 [00:11<00:00,  1.20s/it]\n",
            "Processing S425: 100%|██████████| 11/11 [00:12<00:00,  1.14s/it]\n",
            "Processing S427: 100%|██████████| 11/11 [00:12<00:00,  1.16s/it]\n",
            "Processing S429: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S419: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S421: 100%|██████████| 10/10 [00:12<00:00,  1.27s/it]\n",
            "Processing S423: 100%|██████████| 9/9 [00:10<00:00,  1.22s/it]\n",
            "Processing S428: 100%|██████████| 12/12 [00:13<00:00,  1.15s/it]\n",
            "Processing S426: 100%|██████████| 8/8 [00:09<00:00,  1.14s/it]\n",
            "Processing S408: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S418: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S417: 100%|██████████| 10/10 [00:11<00:00,  1.16s/it]\n",
            "Processing S411: 100%|██████████| 11/11 [00:15<00:00,  1.45s/it]\n",
            "Processing S409: 100%|██████████| 12/12 [00:14<00:00,  1.25s/it]\n",
            "Processing S412: 100%|██████████| 11/11 [00:12<00:00,  1.18s/it]\n",
            "Processing S416: 100%|██████████| 10/10 [00:11<00:00,  1.11s/it]\n",
            "Processing S414: 100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n",
            "Processing S415: 100%|██████████| 11/11 [00:13<00:00,  1.26s/it]\n",
            "Processing S413: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it]\n",
            "Processing S400: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
            "Processing S407: 100%|██████████| 9/9 [00:09<00:00,  1.07s/it]\n",
            "Processing S403: 100%|██████████| 11/11 [00:09<00:00,  1.19it/s]\n",
            "Processing S398: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S405: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
            "Processing S404: 100%|██████████| 11/11 [00:10<00:00,  1.02it/s]\n",
            "Processing S401: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S406: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S402: 100%|██████████| 12/12 [00:14<00:00,  1.21s/it]\n",
            "Processing S399: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S388: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S391: 100%|██████████| 10/10 [00:11<00:00,  1.12s/it]\n",
            "Processing S394: 100%|██████████| 11/11 [00:12<00:00,  1.15s/it]\n",
            "Processing S393: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S390: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S397: 100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n",
            "Processing S389: 100%|██████████| 11/11 [00:12<00:00,  1.13s/it]\n",
            "Processing S395: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S392: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n",
            "Processing S396: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S381: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S385: 100%|██████████| 12/12 [00:14<00:00,  1.19s/it]\n",
            "Processing S376: 100%|██████████| 11/11 [00:12<00:00,  1.17s/it]\n",
            "Processing S387: 100%|██████████| 10/10 [00:11<00:00,  1.11s/it]\n",
            "Processing S383: 100%|██████████| 7/7 [00:09<00:00,  1.31s/it]\n",
            "Processing S375: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
            "Processing S380: 100%|██████████| 11/11 [00:13<00:00,  1.19s/it]\n",
            "Processing S384: 100%|██████████| 11/11 [00:12<00:00,  1.13s/it]\n",
            "Processing S382: 100%|██████████| 12/12 [00:12<00:00,  1.05s/it]\n",
            "Processing S386: 100%|██████████| 12/12 [00:14<00:00,  1.19s/it]\n",
            "Processing S350: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
            "Processing S354: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S351: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S355: 100%|██████████| 9/9 [00:10<00:00,  1.13s/it]\n",
            "Processing S364: 100%|██████████| 9/9 [00:10<00:00,  1.18s/it]\n",
            "Processing S373: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S367: 100%|██████████| 9/9 [00:11<00:00,  1.25s/it]\n",
            "Processing S357: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S353: 100%|██████████| 12/12 [00:14<00:00,  1.19s/it]\n",
            "Processing S352: 100%|██████████| 11/11 [00:12<00:00,  1.12s/it]\n",
            "Processing S341: 100%|██████████| 11/11 [00:12<00:00,  1.16s/it]\n",
            "Processing S333: 100%|██████████| 11/11 [00:15<00:00,  1.44s/it]\n",
            "Processing S335: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
            "Processing S316: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S324: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S321: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]\n",
            "Processing S336: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n",
            "Processing S325: 100%|██████████| 8/8 [00:08<00:00,  1.09s/it]\n",
            "Processing S331: 100%|██████████| 12/12 [00:14<00:00,  1.17s/it]\n",
            "Processing S346: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S307: 100%|██████████| 10/10 [00:12<00:00,  1.29s/it]\n",
            "Processing S313: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S304: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
            "Processing S296: 100%|██████████| 12/12 [00:13<00:00,  1.17s/it]\n",
            "Processing S310: 100%|██████████| 12/12 [00:13<00:00,  1.16s/it]\n",
            "Processing S315: 100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n",
            "Processing S309: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
            "Processing S300: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n",
            "Processing S295: 100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n",
            "Processing S297: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S283: 100%|██████████| 10/10 [00:12<00:00,  1.24s/it]\n",
            "Processing S291: 100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n",
            "Processing S272: 100%|██████████| 11/11 [00:12<00:00,  1.14s/it]\n",
            "Processing S280: 100%|██████████| 11/11 [00:12<00:00,  1.15s/it]\n",
            "Processing S285: 100%|██████████| 8/8 [00:10<00:00,  1.29s/it]\n",
            "Processing S273: 100%|██████████| 12/12 [00:13<00:00,  1.14s/it]\n",
            "Processing S270: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S282: 100%|██████████| 12/12 [00:13<00:00,  1.16s/it]\n",
            "Processing S284: 100%|██████████| 7/7 [00:07<00:00,  1.11s/it]\n",
            "Processing S288: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S253: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
            "Processing S261: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S250: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S258: 100%|██████████| 12/12 [00:14<00:00,  1.19s/it]\n",
            "Processing S243: 100%|██████████| 12/12 [00:13<00:00,  1.16s/it]\n",
            "Processing S263: 100%|██████████| 11/11 [00:12<00:00,  1.13s/it]\n",
            "Processing S254: 100%|██████████| 12/12 [00:14<00:00,  1.18s/it]\n",
            "Processing S249: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S259: 100%|██████████| 12/12 [00:14<00:00,  1.21s/it]\n",
            "Processing S256: 100%|██████████| 12/12 [00:14<00:00,  1.21s/it]\n",
            "Processing S223: 100%|██████████| 9/9 [00:11<00:00,  1.25s/it]\n",
            "Processing S232: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S227: 100%|██████████| 11/11 [00:12<00:00,  1.17s/it]\n",
            "Processing S228: 100%|██████████| 11/11 [00:12<00:00,  1.13s/it]\n",
            "Processing S240: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
            "Processing S236: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
            "Processing S222: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S226: 100%|██████████| 11/11 [00:05<00:00,  2.14it/s]\n",
            "Processing S239: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S225: 100%|██████████| 11/11 [00:16<00:00,  1.48s/it]\n",
            "Processing S214: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
            "Processing S220: 100%|██████████| 9/9 [00:10<00:00,  1.17s/it]\n",
            "Processing S199: 100%|██████████| 11/11 [00:12<00:00,  1.12s/it]\n",
            "Processing S202: 100%|██████████| 12/12 [00:13<00:00,  1.14s/it]\n",
            "Processing S219: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S201: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
            "Processing S215: 100%|██████████| 12/12 [00:15<00:00,  1.26s/it]\n",
            "Processing S212: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S206: 100%|██████████| 12/12 [00:14<00:00,  1.21s/it]\n",
            "Processing S203: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]\n",
            "Processing S193: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S174: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S182: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n",
            "Processing S180: 100%|██████████| 1/1 [00:01<00:00,  1.19s/it]\n",
            "Processing S195: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S194: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
            "Processing S190: 100%|██████████| 11/11 [00:11<00:00,  1.08s/it]\n",
            "Processing S198: 100%|██████████| 11/11 [00:12<00:00,  1.11s/it]\n",
            "Processing S191: 100%|██████████| 12/12 [00:13<00:00,  1.10s/it]\n",
            "Processing S185: 100%|██████████| 12/12 [00:14<00:00,  1.18s/it]\n",
            "Processing S145: 100%|██████████| 9/9 [00:11<00:00,  1.26s/it]\n",
            "Processing S150: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
            "Processing S164: 100%|██████████| 8/8 [00:08<00:00,  1.07s/it]\n",
            "Processing S166: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S153: 100%|██████████| 12/12 [00:13<00:00,  1.10s/it]\n",
            "Processing S173: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n",
            "Processing S148: 100%|██████████| 12/12 [00:13<00:00,  1.16s/it]\n",
            "Processing S171: 100%|██████████| 12/12 [00:13<00:00,  1.16s/it]\n",
            "Processing S146: 100%|██████████| 11/11 [00:11<00:00,  1.04s/it]\n",
            "Processing S163: 100%|██████████| 12/12 [00:08<00:00,  1.48it/s]\n",
            "Processing S124: 100%|██████████| 11/11 [00:13<00:00,  1.26s/it]\n",
            "Processing S117: 100%|██████████| 11/11 [00:14<00:00,  1.31s/it]\n",
            "Processing S120: 100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n",
            "Processing S132: 100%|██████████| 9/9 [00:09<00:00,  1.09s/it]\n",
            "Processing S134: 100%|██████████| 12/12 [00:14<00:00,  1.18s/it]\n",
            "Processing S142: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
            "Processing S118: 100%|██████████| 12/12 [00:14<00:00,  1.19s/it]\n",
            "Processing S138: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S130: 100%|██████████| 10/10 [00:12<00:00,  1.23s/it]\n",
            "Processing S133: 100%|██████████| 9/9 [00:09<00:00,  1.07s/it]\n",
            "Processing S099: 100%|██████████| 11/11 [00:12<00:00,  1.15s/it]\n",
            "Processing S098: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
            "Processing S088: 100%|██████████| 11/11 [00:13<00:00,  1.20s/it]\n",
            "Processing S093: 100%|██████████| 9/9 [00:04<00:00,  2.09it/s]\n",
            "Processing S108: 100%|██████████| 10/10 [00:12<00:00,  1.21s/it]\n",
            "Processing S112: 100%|██████████| 11/11 [00:12<00:00,  1.16s/it]\n",
            "Processing S095: 100%|██████████| 10/10 [00:11<00:00,  1.13s/it]\n",
            "Processing S111: 100%|██████████| 11/11 [00:12<00:00,  1.14s/it]\n",
            "Processing S096: 100%|██████████| 11/11 [00:12<00:00,  1.16s/it]\n",
            "Processing S101: 100%|██████████| 11/11 [00:13<00:00,  1.23s/it]\n",
            "Processing S085: 100%|██████████| 8/8 [00:13<00:00,  1.71s/it]\n",
            "Processing S073: 100%|██████████| 10/10 [00:04<00:00,  2.13it/s]\n",
            "Processing S078: 100%|██████████| 9/9 [00:11<00:00,  1.26s/it]\n",
            "Processing S059: 100%|██████████| 10/10 [00:11<00:00,  1.16s/it]\n",
            "Processing S065: 100%|██████████| 12/12 [00:13<00:00,  1.15s/it]\n",
            "Processing S064: 100%|██████████| 11/11 [00:12<00:00,  1.14s/it]\n",
            "Processing S058: 100%|██████████| 9/9 [00:11<00:00,  1.25s/it]\n",
            "Processing S068: 100%|██████████| 12/12 [00:14<00:00,  1.17s/it]\n",
            "Processing S069: 100%|██████████| 9/9 [00:10<00:00,  1.20s/it]\n",
            "Processing S076: 100%|██████████| 9/9 [00:12<00:00,  1.34s/it]\n",
            "Processing S045: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S052: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S036: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S051: 100%|██████████| 9/9 [00:10<00:00,  1.13s/it]\n",
            "Processing S046: 100%|██████████| 12/12 [00:13<00:00,  1.15s/it]\n",
            "Processing S044: 100%|██████████| 12/12 [00:14<00:00,  1.19s/it]\n",
            "Processing S048: 100%|██████████| 9/9 [00:11<00:00,  1.25s/it]\n",
            "Processing S033: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S054: 100%|██████████| 10/10 [00:12<00:00,  1.22s/it]\n",
            "Processing S032: 100%|██████████| 12/12 [00:13<00:00,  1.16s/it]\n",
            "Processing S029: 100%|██████████| 12/12 [00:13<00:00,  1.15s/it]\n",
            "Processing S031: 100%|██████████| 10/10 [00:11<00:00,  1.16s/it]\n",
            "Processing S015: 100%|██████████| 9/9 [00:10<00:00,  1.19s/it]\n",
            "Processing S027: 100%|██████████| 12/12 [00:14<00:00,  1.20s/it]\n",
            "Processing S006: 100%|██████████| 11/11 [00:13<00:00,  1.22s/it]\n",
            "Processing S022: 100%|██████████| 12/12 [00:13<00:00,  1.10s/it]\n",
            "Processing S013: 100%|██████████| 12/12 [00:14<00:00,  1.17s/it]\n",
            "Processing S030: 100%|██████████| 11/11 [00:12<00:00,  1.13s/it]\n",
            "Processing S023: 100%|██████████| 12/12 [00:10<00:00,  1.15it/s]\n",
            "Processing S008: 100%|██████████| 11/11 [00:13<00:00,  1.21s/it]\n",
            "Processing S001: 100%|██████████| 12/12 [00:14<00:00,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ekstraksi fitur selesai dan embedding wajah disimpan sebagai basis data.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import insightface\n",
        "import pickle\n",
        "\n",
        "# Direktori yang berisi hasil face alignment pada training set\n",
        "aligned_data_dir = '/content/drive/My Drive/Colab Notebooks/nist_2/AlignedData/'\n",
        "\n",
        "# Direktori untuk menyimpan basis data embedding\n",
        "output_embedding_file = '/content/drive/My Drive/Colab Notebooks/nist_2/face_embeddings.pkl'\n",
        "\n",
        "# Muat model ArcFace untuk ekstraksi fitur\n",
        "model = insightface.app.FaceAnalysis(providers=['CPUExecutionProvider'])  # Ubah ke GPU jika ada\n",
        "model.prepare(ctx_id=0, det_size=(640, 640))  # Sesuaikan dengan kebutuhan\n",
        "\n",
        "# Dictionary untuk menyimpan embedding dan label\n",
        "embeddings_dict = {}\n",
        "\n",
        "# Loop melalui setiap subfolder di direktori aligned data\n",
        "for subfolder in os.listdir(aligned_data_dir):\n",
        "    subfolder_path = os.path.join(aligned_data_dir, subfolder)\n",
        "\n",
        "    if os.path.isdir(subfolder_path):\n",
        "        embeddings_dict[subfolder] = []  # Inisialisasi daftar untuk setiap subfolder (label)\n",
        "\n",
        "        # Loop melalui setiap gambar di subfolder\n",
        "        for file_name in tqdm(os.listdir(subfolder_path), desc=f\"Processing {subfolder}\"):\n",
        "            if file_name.endswith('.ppm'):\n",
        "                file_path = os.path.join(subfolder_path, file_name)\n",
        "\n",
        "                # Buka gambar dan konversi ke format RGB\n",
        "                image = Image.open(file_path).convert('RGB')\n",
        "                image_np = np.array(image)\n",
        "\n",
        "                # Ekstraksi fitur menggunakan ArcFace\n",
        "                faces = model.get(image_np)\n",
        "\n",
        "                # Proses hanya jika ada wajah yang terdeteksi\n",
        "                if faces:\n",
        "                    # Ambil embedding dari wajah pertama yang terdeteksi\n",
        "                    embedding = faces[0].embedding\n",
        "\n",
        "                    # Simpan embedding di dictionary sesuai dengan label subfoldernya\n",
        "                    embeddings_dict[subfolder].append(embedding)\n",
        "\n",
        "# Simpan embedding dan label ke file untuk basis data\n",
        "with open(output_embedding_file, 'wb') as f:\n",
        "    pickle.dump(embeddings_dict, f)\n",
        "\n",
        "print(\"Ekstraksi fitur selesai dan embedding wajah disimpan sebagai basis data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4pRYkWoFF9-",
        "outputId": "632c3abe-d76b-4581-f6b0-71918a09d5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model k-NN telah selesai dilatih.\n",
            "Akurasi awal model k-NN pada data test: 98.20%\n",
            "Model k-NN disimpan di /content/drive/My Drive/Colab Notebooks/nist_2/knn_face_recognition_model.pkl.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import joblib  # Untuk menyimpan model\n",
        "\n",
        "# Path ke file embedding yang sudah disimpan\n",
        "embedding_file = '/content/drive/My Drive/Colab Notebooks/nist_2/face_embeddings.pkl'\n",
        "\n",
        "# Path untuk menyimpan model k-NN yang sudah dilatih\n",
        "model_save_path = '/content/drive/My Drive/Colab Notebooks/nist_2/knn_face_recognition_model.pkl'\n",
        "\n",
        "# Load embedding dan label dari file\n",
        "with open(embedding_file, 'rb') as f:\n",
        "    embeddings_dict = pickle.load(f)\n",
        "\n",
        "# Siapkan list untuk embedding dan label\n",
        "X = []  # Embedding features\n",
        "y = []  # Labels\n",
        "\n",
        "# Pisahkan embedding dan label dari dictionary\n",
        "for label, embeddings in embeddings_dict.items():\n",
        "    for embedding in embeddings:\n",
        "        X.append(embedding)\n",
        "        y.append(label)\n",
        "\n",
        "# Konversi ke array numpy untuk kompatibilitas dengan scikit-learn\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Split data menjadi train dan test set untuk evaluasi (opsional)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Inisialisasi model k-NN, tentukan jumlah tetangga (k)\n",
        "k = 5  # Anda bisa menyesuaikan k berdasarkan performa\n",
        "knn_model = KNeighborsClassifier(n_neighbors=k, metric='cosine')\n",
        "\n",
        "# Latih model dengan data train\n",
        "knn_model.fit(X_train, y_train)\n",
        "print(\"Model k-NN telah selesai dilatih.\")\n",
        "\n",
        "# Evaluasi model pada data test untuk melihat performa awal\n",
        "y_pred = knn_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Akurasi awal model k-NN pada data test: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Simpan model k-NN yang telah dilatih\n",
        "joblib.dump(knn_model, model_save_path)\n",
        "print(f\"Model k-NN disimpan di {model_save_path}.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}